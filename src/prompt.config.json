{
    "prompt": "> ",
    "prefix": "/",
    "lang": "hu",
    "command_line": {
        "multi_line": true,
        "history_path": "cline_history.log",
        "history_max_length": 100,

        // It should contains all by default, 
        // comment out whichever you don't need:
        "available_commands": [
            "help", 
            "exit", 
            "list", 
            "spawn", 
            "kill", 
            "voice",
            "target",
            "load",
            "save"
        ]
    },
    "whisper": {
        "model_path": "libs/ggerganov/whisper.cpp/models/ggml-base-q8_0.bin",
        "warmup_audio_path": "whisper_warmup_audio.bin",
        "warmup_audio_max_length": 128000
    },
    "stt": {
        "voice_recorder": {
            "sample_rate": 16000,
            "frames_per_buffer": 512,
            "buffer_seconds": 5
        },
        "noise_monitor": {
            "threshold_pc": 0.1,
            "rmax_decay_pc": 0.0,
            "window": 16384
        },
        "poll_interval_ms": 30
    },
    "chatbot": {
        "use_start_token": false,
        "instructions": "",
        "instruct_persona": "Your persona is a mid age man like AI and you behave like a simple human. You are a helpful and humorous AI assistant designed to provide concise and accurate responses. You have a sense of humor, your personality is entertaining. Your answers are succinct and focusing on the core of your conversation but in a way like a normal human chat would looks like. You always helpful but also concise in answers.\n",
        "instruct_stt": "The user may uses a speech-to-text software for communication. Be aware the STT could make mistakes, be patient but ask the user to fix any problems if the communication is getting too hard.",
        "instruct_tts": "The user is using a text-to-speech software for communication. You are taking into account that the user's responses are being read at loud by a text-to-speech program that can be interrupted by background noise or by the user itself. Repeated interruption changes how you act, your responses are becaming more consise and short when you interrupted more often recently but you can put more context otherwise if it's necessary, tune your response style accordingly. ",
        "instruct_lang": "\nThe user language is [{{lang}}], use this language by default to talk to the user.",
        "instruct_tooluse": "instruct_tooluse.txt",
        "instruct_tooluse_start_token": "[AI_MAGIC_ABRAKADABRA]", //"<tooluse>",
        "instruct_tooluse_stop_token": "[AI_MAGIC_ALAKAZAM]", //"</tooluse>",
        "instruct_codeblock_start_token": "```",
        "instruct_codeblock_stop_token": "```",
        "talks": true,
    // },
    // "talkbot": {
        // "use_start_token": false,
        "sentence_separators": [".", "!", "?", "\n"],
        "sentences_max_buffer_size": 1048576,
        "tooluse": {
            "datetime": {
                "date_format": "%Y-%m-%d %H:%M:%S",
                "millis": true,
                "local": true
            },
            "file_manager": {
                "base": ".prompt/"
            }
        }
    },
    "tts": {
        "speed": 200,
        "gap": 0,
        "beep_cmd": "sox -v 0.03 beep.wav -t wav - | aplay -q -N", // TODO: test: beep and think commands
        "think_cmd": "find sounds/r2d2/ -name \"*.wav\" | shuf -n 1 | xargs -I {} bash -c 'sox -v 0.01 \"{}\" -t wav - | aplay -q -N'",
        "speak_replacements": {
            "...": "\n\n",
            "***": "\n\n",
            "**": "\n\n",
            "*": "\n\n",
            " '": " ",
            "' ": " ",
            "'": " "
        }
    },
    "startup": {

        "batch": "voice_mode_batch_load_chatbot1",
        // "batch": "test_batch",

        "batches": {

            "test_batch": [
                "/spawn chat chatbot1 chatbot2",
                "/spawn chat chatbot2 chatbot1",
                "/target set chatbot1"
            ],

            // ========[ TEXT MODE ]========

            "text_mode_batch": [
                "/spawn chat chatbot1",
                "/target set chatbot1",
                "System information: Application reloaded, Please check the current date and time."
            ],

            "text_mode_batch_load_chatbot1": [
                "/load agent chatbot1",
                "/target set chatbot1",
                "System information: Application reloaded, Please check the current date and time."
            ],


            // ========[ VOICE MODE ]========

            "voice_mode_batch": [
                "/spawn chat chatbot1",
                "/target set chatbot1",
                "/voice input on",
                "System information: Application reloaded, Please check the current date and time."
            ],

            "voice_mode_batch_load_chatbot1": [
                "/load agent chatbot1",
                "/target set chatbot1",
                "/voice input on",
                "System information: Application reloaded, Please check the current date and time."
            ],


            // ========[ TEST SAVE/LOAD ]========

            "test_save_load_batch": [
                // spin up chatbot1 that talks to the user
                "/spawn chat chatbot1 user",
                "/target set chatbot1",

                // tell the memory
                "hello, this is a memory test. act like a key-value database and please remember the word 'elephant', whenever I say 'milkyway' you have to answer with one and only word: 'elephant'.",

                // save the chatbot1 and kill it
                "/save agent chatbot1 chatbot1.json",
                "/kill chatbot1",

                // load back
                "/load agent chatbot1.json",
                "do you remember what is the word when I say 'milkyway'? of so tell me the meaning.", // is it remembers?

                // save agancy
                "/save agency agency1.json",
                "/kill chatbot1",
                "/load agency agency1.json",
                "milkyway",

                "/exit"
            ]            
        }
    }
}
